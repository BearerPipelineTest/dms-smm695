{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-05T08:13:31.974944Z",
     "start_time": "2020-06-05T08:13:31.968492Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Week 6 - SMM695\n",
    "\n",
    "Matteo Devigili\n",
    "\n",
    "June, 24th 2020\n",
    "\n",
    "[_PySpark_](https://spark.apache.org/docs/latest/api/python/index.html#): during this lecture, we will approach Spark through Python\n",
    "\n",
    "<img src=\"images/_1.png\" width=\"20%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Agenda**:\n",
    "1. Introduction to Spark\n",
    "1. Installing PySpark\n",
    "1. PySpark Basics\n",
    "1. PySpark and Pandas\n",
    "1. PySpark and SQL\n",
    "1. Load data from your DBMS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Introduction to Spark\n",
    "\n",
    "**Big Data Challenge**:\n",
    "\n",
    "* Cost of storing data has dropped\n",
    "* The need for parallel computation has increased\n",
    "\n",
    "![IBM Blue Gene\\L](https://www.ibm.com/ibm/history/ibm100/images/icp/U225116Q82800V30/us__en_us__ibm100__blue_gene__man_next_blue_gene__620x350.jpg)\n",
    "**Note**: [IBM Blue Gen\\L](https://www.ibm.com/ibm/history/ibm100/us/en/icons/bluegene/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-14T09:06:51.596422Z",
     "start_time": "2020-06-14T09:06:51.588599Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**What is [Apache Spark](https://spark.apache.org)**?\n",
    "\n",
    "> \"Apache Spark is a unified computing engine and a set of libraries for parallel data processing on computer clusters\"\n",
    "\n",
    "[Chambers and Zaharia 2018](#references)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Programming Languages Supported**:\n",
    "<img src=\"images/_0.png\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-13T10:49:40.128171Z",
     "start_time": "2020-06-13T10:49:40.122611Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Spark's philosophy**:\n",
    "\n",
    "* *Unified*: Spark offers a large variety of data analytics tools\n",
    "* *Computing Engine*: Spark focuses on computing, not on storage\n",
    "* *Libraries*: Spark has different libraries to perform several tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Apache Spark Libraries**:\n",
    "\n",
    "* *Spark SQL*\n",
    "* *Spark Streaming*\n",
    "* *Spark MLlib*\n",
    "* *Spark GraphX*\n",
    "\n",
    "[Third-party projects](https://spark.apache.org/third-party-projects.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Spark Application**:\n",
    "\n",
    "| Component ||Role |\n",
    "|----|----|---|\n",
    "| *Spark Driver*| | Execute user-defined tasks |\n",
    "| *Cluster Manager* | | Manage workers nodes|\n",
    "| *Executors* | | Execute tasks |\n",
    "\n",
    "<img src=\"images/_5.png\" width=80%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**From Python to Spark code and back**:\n",
    "\n",
    "![The relationship between the SparkSession and Sparkâ€™s Language API\n",
    "](https://www.oreilly.com/library/view/spark-the-definitive/9781491912201/assets/spdg_0202.png)\n",
    "\n",
    "Source: _Bill Chambers, Matei Zaharia 2018_ (p. 23)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Installing PySpark\n",
    "\n",
    "There are several ways to set-up PySpark on your local machine. Here, two methods are discussed:\n",
    "* Pure-python users: \n",
    "```python\n",
    "pip install pyspark\n",
    "```\n",
    "* Conda users:\n",
    "```python\n",
    "conda install pyspark\n",
    "```\n",
    "Further info at [Spark Download page](https://spark.apache.org/downloads.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-06T08:08:30.066602Z",
     "start_time": "2020-06-06T08:08:30.056202Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Requirements\n",
    "\n",
    "Pay attention to the following:\n",
    "\n",
    ">Spark runs on Java 8\n",
    "\n",
    "Check java version running on your machine. Type the following on your terminal:\n",
    "```python\n",
    "java -version\n",
    "```\n",
    "\n",
    "If you are running a different Java version, install java 8! Check out [Spark Downloading info](https://spark.apache.org/docs/latest/#downloading)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# PySpark - Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T10:42:06.797592Z",
     "start_time": "2020-06-19T10:42:06.726681Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#to create a spark session object\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# functions\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "# data types\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "# import datetime \n",
    "from datetime import date as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* More info on **Functions** at these [linkOne](https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#module-pyspark.sql.functions) & [linkTwo](https://spark.apache.org/docs/2.3.0/api/sql/index.html#year)\n",
    "* More info on **Data Types** at this [link](https://spark.apache.org/docs/latest/sql-reference.html#tab_python_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Opening a Session\n",
    "\n",
    "The **SparkSession** is a driver process that enables:\n",
    "\n",
    "* to control our Spark Application\n",
    "* to execute user-defined manipulations\n",
    "\n",
    "Check this [link](https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.SparkSession) for further reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T10:43:44.101440Z",
     "start_time": "2020-06-19T10:43:36.024999Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# to open a Session\n",
    "spark = SparkSession.builder.appName('last_dance').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Spark UI**\n",
    "\n",
    "<img src=\"images/_6.png\" width=60%>\n",
    "\n",
    "The spark UI is useful to monitor your application. You have the following tabs:\n",
    "\n",
    "* *Jobs*: info concerning Spark jobs\n",
    "* *Stages*: info on individual stages and their tasks\n",
    "* *Storage*: info on data that is currently in our spark application\n",
    "* *Environment*: info on configurations and current settings of our application\n",
    "* *Executors*: info on the executors that run our application\n",
    "* *SQL*: refers to both SQL and DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T10:44:27.071236Z",
     "start_time": "2020-06-19T10:44:27.037413Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://172.20.10.2:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.6</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>last_dance</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1166f5f90>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Create Dataframe\n",
    "\n",
    "In order to create a dataframe from scratch, we need to:\n",
    "1. Create a schema, passing:\n",
    "  * Column names\n",
    "  * Data types\n",
    "1. Pass values as an array of tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T10:48:18.891858Z",
     "start_time": "2020-06-19T10:48:16.949258Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- first_name: string (nullable = true)\n",
      " |-- last_name: string (nullable = true)\n",
      " |-- dob: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Here, I define a schema\n",
    "# .add(field, data_type=None, nullable=True, metadata=None)\n",
    "\n",
    "schema = StructType().add(\"id\", \"integer\", True).add(\"first_name\", \"string\", True).add(\n",
    "    \"last_name\", \"string\", True).add(\"dob\", \"date\", True)\n",
    "\n",
    "'''\n",
    "schema = StructType().add(\"id\", IntegerType(), True).add(\"first_name\", StringType(), True).add(\n",
    "    \"last_name\", StringType(), True).add(\"dob\", DateType(), True)\n",
    "'''\n",
    "\n",
    "# Then, I can pass some values\n",
    "df = spark.createDataFrame([(1, 'Michael', \"Jordan\", dt(1963, 2, 17)),\n",
    "                            (2, 'Scottie', \"Pippen\", dt(1965, 9, 25)),\n",
    "                            (3, 'Dennis', \"Rodman\", dt(1961, 5, 16))],\n",
    "                           schema=schema)\n",
    "\n",
    "# Let's explore Schema structure\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T10:49:40.465738Z",
     "start_time": "2020-06-19T10:49:37.582205Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+----------+---+\n",
      "| id|first_name|last_name|       dob|age|\n",
      "+---+----------+---------+----------+---+\n",
      "|  1|   Michael|   Jordan|1963-02-17| 57|\n",
      "|  2|   Scottie|   Pippen|1965-09-25| 55|\n",
      "|  3|    Dennis|   Rodman|1961-05-16| 59|\n",
      "+---+----------+---------+----------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We can also leverage on functions to create a new column\n",
    "df=df.withColumn('age', F.year(F.current_date()) - F.year(df.dob))\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Transformations**\n",
    "\n",
    "* Immutability: once created, data structures can not be changed\n",
    "* Lazy evaluation: computational instructions will be executed at the very last"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Actions**\n",
    "\n",
    "* view data\n",
    "* collect data\n",
    "* write to output data sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# PySpark and Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Load a csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Loading a csv file from you computer, you need to type:\n",
    "* Pands:\n",
    "  * db = pd.read_csv('path/to/movies.csv')\n",
    "* Pyspark:\n",
    "  * df = spark.read.csv('path/to/movies.csv', header=True, inferSchema=True)\n",
    "\n",
    "Here, we will import a csv directly from GitHub. Data are provided by [FiveThirtyEight](https://github.com/fivethirtyeight)\n",
    "[<img src=\"images/_2.png\" width=\"50%\">](https://fivethirtyeight.com/features/the-dollar-and-cents-case-against-hollywoods-exclusion-of-women/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T11:00:05.506049Z",
     "start_time": "2020-06-19T11:00:05.501696Z"
    }
   },
   "outputs": [],
   "source": [
    "# import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# import SparkFiles\n",
    "from pyspark import SparkFiles\n",
    "\n",
    "# target dataset\n",
    "url = 'https://raw.githubusercontent.com/fivethirtyeight/data/master/bechdel/movies.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T11:01:27.578138Z",
     "start_time": "2020-06-19T11:01:21.652064Z"
    }
   },
   "outputs": [],
   "source": [
    "# loading data with pandas\n",
    "db = pd.read_csv(url)\n",
    "\n",
    "# loading data with pyspark\n",
    "spark.sparkContext.addFile(url)\n",
    "df = spark.read.csv(SparkFiles.get('movies.csv'), header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T08:55:00.801919Z",
     "start_time": "2020-06-19T08:55:00.785095Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1794 entries, 0 to 1793\n",
      "Data columns (total 15 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   year            1794 non-null   int64  \n",
      " 1   imdb            1794 non-null   object \n",
      " 2   title           1794 non-null   object \n",
      " 3   test            1794 non-null   object \n",
      " 4   clean_test      1794 non-null   object \n",
      " 5   binary          1794 non-null   object \n",
      " 6   budget          1794 non-null   int64  \n",
      " 7   domgross        1777 non-null   float64\n",
      " 8   intgross        1783 non-null   float64\n",
      " 9   code            1794 non-null   object \n",
      " 10  budget_2013$    1794 non-null   int64  \n",
      " 11  domgross_2013$  1776 non-null   float64\n",
      " 12  intgross_2013$  1783 non-null   float64\n",
      " 13  period code     1615 non-null   float64\n",
      " 14  decade code     1615 non-null   float64\n",
      "dtypes: float64(6), int64(3), object(6)\n",
      "memory usage: 210.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# pandas info\n",
    "db.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T08:55:06.974456Z",
     "start_time": "2020-06-19T08:55:06.966256Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- year: integer (nullable = true)\n",
      " |-- imdb: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- test: string (nullable = true)\n",
      " |-- clean_test: string (nullable = true)\n",
      " |-- binary: string (nullable = true)\n",
      " |-- budget: integer (nullable = true)\n",
      " |-- domgross: string (nullable = true)\n",
      " |-- intgross: string (nullable = true)\n",
      " |-- code: string (nullable = true)\n",
      " |-- budget_2013$: integer (nullable = true)\n",
      " |-- domgross_2013$: string (nullable = true)\n",
      " |-- intgross_2013$: string (nullable = true)\n",
      " |-- period code: integer (nullable = true)\n",
      " |-- decade code: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# pyspark schema\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T08:55:07.890618Z",
     "start_time": "2020-06-19T08:55:07.861658Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>imdb</th>\n",
       "      <th>title</th>\n",
       "      <th>test</th>\n",
       "      <th>clean_test</th>\n",
       "      <th>binary</th>\n",
       "      <th>budget</th>\n",
       "      <th>domgross</th>\n",
       "      <th>intgross</th>\n",
       "      <th>code</th>\n",
       "      <th>budget_2013$</th>\n",
       "      <th>domgross_2013$</th>\n",
       "      <th>intgross_2013$</th>\n",
       "      <th>period code</th>\n",
       "      <th>decade code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013</td>\n",
       "      <td>tt1711425</td>\n",
       "      <td>21 &amp;amp; Over</td>\n",
       "      <td>notalk</td>\n",
       "      <td>notalk</td>\n",
       "      <td>FAIL</td>\n",
       "      <td>13000000</td>\n",
       "      <td>25682380.0</td>\n",
       "      <td>42195766.0</td>\n",
       "      <td>2013FAIL</td>\n",
       "      <td>13000000</td>\n",
       "      <td>25682380.0</td>\n",
       "      <td>42195766.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012</td>\n",
       "      <td>tt1343727</td>\n",
       "      <td>Dredd 3D</td>\n",
       "      <td>ok-disagree</td>\n",
       "      <td>ok</td>\n",
       "      <td>PASS</td>\n",
       "      <td>45000000</td>\n",
       "      <td>13414714.0</td>\n",
       "      <td>40868994.0</td>\n",
       "      <td>2012PASS</td>\n",
       "      <td>45658735</td>\n",
       "      <td>13611086.0</td>\n",
       "      <td>41467257.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013</td>\n",
       "      <td>tt2024544</td>\n",
       "      <td>12 Years a Slave</td>\n",
       "      <td>notalk-disagree</td>\n",
       "      <td>notalk</td>\n",
       "      <td>FAIL</td>\n",
       "      <td>20000000</td>\n",
       "      <td>53107035.0</td>\n",
       "      <td>158607035.0</td>\n",
       "      <td>2013FAIL</td>\n",
       "      <td>20000000</td>\n",
       "      <td>53107035.0</td>\n",
       "      <td>158607035.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013</td>\n",
       "      <td>tt1272878</td>\n",
       "      <td>2 Guns</td>\n",
       "      <td>notalk</td>\n",
       "      <td>notalk</td>\n",
       "      <td>FAIL</td>\n",
       "      <td>61000000</td>\n",
       "      <td>75612460.0</td>\n",
       "      <td>132493015.0</td>\n",
       "      <td>2013FAIL</td>\n",
       "      <td>61000000</td>\n",
       "      <td>75612460.0</td>\n",
       "      <td>132493015.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013</td>\n",
       "      <td>tt0453562</td>\n",
       "      <td>42</td>\n",
       "      <td>men</td>\n",
       "      <td>men</td>\n",
       "      <td>FAIL</td>\n",
       "      <td>40000000</td>\n",
       "      <td>95020213.0</td>\n",
       "      <td>95020213.0</td>\n",
       "      <td>2013FAIL</td>\n",
       "      <td>40000000</td>\n",
       "      <td>95020213.0</td>\n",
       "      <td>95020213.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year       imdb             title             test clean_test binary  \\\n",
       "0  2013  tt1711425     21 &amp; Over           notalk     notalk   FAIL   \n",
       "1  2012  tt1343727          Dredd 3D      ok-disagree         ok   PASS   \n",
       "2  2013  tt2024544  12 Years a Slave  notalk-disagree     notalk   FAIL   \n",
       "3  2013  tt1272878            2 Guns           notalk     notalk   FAIL   \n",
       "4  2013  tt0453562                42              men        men   FAIL   \n",
       "\n",
       "     budget    domgross     intgross      code  budget_2013$  domgross_2013$  \\\n",
       "0  13000000  25682380.0   42195766.0  2013FAIL      13000000      25682380.0   \n",
       "1  45000000  13414714.0   40868994.0  2012PASS      45658735      13611086.0   \n",
       "2  20000000  53107035.0  158607035.0  2013FAIL      20000000      53107035.0   \n",
       "3  61000000  75612460.0  132493015.0  2013FAIL      61000000      75612460.0   \n",
       "4  40000000  95020213.0   95020213.0  2013FAIL      40000000      95020213.0   \n",
       "\n",
       "   intgross_2013$  period code  decade code  \n",
       "0      42195766.0          1.0          1.0  \n",
       "1      41467257.0          1.0          1.0  \n",
       "2     158607035.0          1.0          1.0  \n",
       "3     132493015.0          1.0          1.0  \n",
       "4      95020213.0          1.0          1.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pandas fetch 5\n",
    "db.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T08:55:12.386242Z",
     "start_time": "2020-06-19T08:55:11.952901Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+----------------+---------------+----------+------+--------+--------+---------+--------+------------+--------------+--------------+-----------+-----------+\n",
      "|year|     imdb|           title|           test|clean_test|binary|  budget|domgross| intgross|    code|budget_2013$|domgross_2013$|intgross_2013$|period code|decade code|\n",
      "+----+---------+----------------+---------------+----------+------+--------+--------+---------+--------+------------+--------------+--------------+-----------+-----------+\n",
      "|2013|tt1711425|   21 &amp; Over|         notalk|    notalk|  FAIL|13000000|25682380| 42195766|2013FAIL|    13000000|      25682380|      42195766|          1|          1|\n",
      "|2012|tt1343727|        Dredd 3D|    ok-disagree|        ok|  PASS|45000000|13414714| 40868994|2012PASS|    45658735|      13611086|      41467257|          1|          1|\n",
      "|2013|tt2024544|12 Years a Slave|notalk-disagree|    notalk|  FAIL|20000000|53107035|158607035|2013FAIL|    20000000|      53107035|     158607035|          1|          1|\n",
      "|2013|tt1272878|          2 Guns|         notalk|    notalk|  FAIL|61000000|75612460|132493015|2013FAIL|    61000000|      75612460|     132493015|          1|          1|\n",
      "|2013|tt0453562|              42|            men|       men|  FAIL|40000000|95020213| 95020213|2013FAIL|    40000000|      95020213|      95020213|          1|          1|\n",
      "+----+---------+----------------+---------------+----------+------+--------+--------+---------+--------+------------+--------------+--------------+-----------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(year=2013, imdb='tt1711425', title='21 &amp; Over', test='notalk', clean_test='notalk', binary='FAIL', budget=13000000, domgross='25682380', intgross='42195766', code='2013FAIL', budget_2013$=13000000, domgross_2013$='25682380', intgross_2013$='42195766', period code=1, decade code=1),\n",
       " Row(year=2012, imdb='tt1343727', title='Dredd 3D', test='ok-disagree', clean_test='ok', binary='PASS', budget=45000000, domgross='13414714', intgross='40868994', code='2012PASS', budget_2013$=45658735, domgross_2013$='13611086', intgross_2013$='41467257', period code=1, decade code=1),\n",
       " Row(year=2013, imdb='tt2024544', title='12 Years a Slave', test='notalk-disagree', clean_test='notalk', binary='FAIL', budget=20000000, domgross='53107035', intgross='158607035', code='2013FAIL', budget_2013$=20000000, domgross_2013$='53107035', intgross_2013$='158607035', period code=1, decade code=1),\n",
       " Row(year=2013, imdb='tt1272878', title='2 Guns', test='notalk', clean_test='notalk', binary='FAIL', budget=61000000, domgross='75612460', intgross='132493015', code='2013FAIL', budget_2013$=61000000, domgross_2013$='75612460', intgross_2013$='132493015', period code=1, decade code=1),\n",
       " Row(year=2013, imdb='tt0453562', title='42', test='men', clean_test='men', binary='FAIL', budget=40000000, domgross='95020213', intgross='95020213', code='2013FAIL', budget_2013$=40000000, domgross_2013$='95020213', intgross_2013$='95020213', period code=1, decade code=1)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pyspark fetch 5\n",
    "df.show(5)\n",
    "\n",
    "df.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T08:55:13.256545Z",
     "start_time": "2020-06-19T08:55:13.233172Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>imdb</th>\n",
       "      <th>title</th>\n",
       "      <th>test</th>\n",
       "      <th>clean_test</th>\n",
       "      <th>binary</th>\n",
       "      <th>budget</th>\n",
       "      <th>domgross</th>\n",
       "      <th>intgross</th>\n",
       "      <th>code</th>\n",
       "      <th>budget_2013$</th>\n",
       "      <th>domgross_2013$</th>\n",
       "      <th>intgross_2013$</th>\n",
       "      <th>period code</th>\n",
       "      <th>decade code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1793</th>\n",
       "      <td>1970</td>\n",
       "      <td>tt0065466</td>\n",
       "      <td>Beyond the Valley of the Dolls</td>\n",
       "      <td>ok</td>\n",
       "      <td>ok</td>\n",
       "      <td>PASS</td>\n",
       "      <td>1000000</td>\n",
       "      <td>9000000.0</td>\n",
       "      <td>9000000.0</td>\n",
       "      <td>1970PASS</td>\n",
       "      <td>5997631</td>\n",
       "      <td>53978683.0</td>\n",
       "      <td>53978683.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      year       imdb                           title test clean_test binary  \\\n",
       "1793  1970  tt0065466  Beyond the Valley of the Dolls   ok         ok   PASS   \n",
       "\n",
       "       budget   domgross   intgross      code  budget_2013$  domgross_2013$  \\\n",
       "1793  1000000  9000000.0  9000000.0  1970PASS       5997631      53978683.0   \n",
       "\n",
       "      intgross_2013$  period code  decade code  \n",
       "1793      53978683.0          NaN          NaN  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pandas filtering:\n",
    "db[db.year == 1970]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T08:55:15.168109Z",
     "start_time": "2020-06-19T08:55:14.901104Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+--------------------+----+----------+------+-------+--------+--------+--------+------------+--------------+--------------+-----------+-----------+\n",
      "|year|     imdb|               title|test|clean_test|binary| budget|domgross|intgross|    code|budget_2013$|domgross_2013$|intgross_2013$|period code|decade code|\n",
      "+----+---------+--------------------+----+----------+------+-------+--------+--------+--------+------------+--------------+--------------+-----------+-----------+\n",
      "|1970|tt0065466|Beyond the Valley...|  ok|        ok|  PASS|1000000| 9000000| 9000000|1970PASS|     5997631|      53978683|      53978683|       null|       null|\n",
      "+----+---------+--------------------+----+----------+------+-------+--------+--------+--------+------------+--------------+--------------+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# pyspark filtering:\n",
    "df[df.year == 1970].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T08:55:16.211734Z",
     "start_time": "2020-06-19T08:55:16.201602Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pandas db.columns:\n",
      "===================\n",
      "Index(['year', 'imdb', 'title', 'test', 'clean_test', 'binary', 'budget',\n",
      "       'domgross', 'intgross', 'code', 'budget_2013$', 'domgross_2013$',\n",
      "       'intgross_2013$', 'period code', 'decade code'],\n",
      "      dtype='object')\n",
      "\n",
      "PySpark df.columns:\n",
      "===================\n",
      "['year', 'imdb', 'title', 'test', 'clean_test', 'binary', 'budget', 'domgross', 'intgross', 'code', 'budget_2013$', 'domgross_2013$', 'intgross_2013$', 'period code', 'decade code']\n",
      "\n",
      "Pandas db.dtype:\n",
      "===================\n",
      "year                int64\n",
      "imdb               object\n",
      "title              object\n",
      "test               object\n",
      "clean_test         object\n",
      "binary             object\n",
      "budget              int64\n",
      "domgross          float64\n",
      "intgross          float64\n",
      "code               object\n",
      "budget_2013$        int64\n",
      "domgross_2013$    float64\n",
      "intgross_2013$    float64\n",
      "period code       float64\n",
      "decade code       float64\n",
      "dtype: object\n",
      "\n",
      "PySpark df.dtypes:\n",
      "===================\n",
      "[('year', 'int'), ('imdb', 'string'), ('title', 'string'), ('test', 'string'), ('clean_test', 'string'), ('binary', 'string'), ('budget', 'int'), ('domgross', 'string'), ('intgross', 'string'), ('code', 'string'), ('budget_2013$', 'int'), ('domgross_2013$', 'string'), ('intgross_2013$', 'string'), ('period code', 'int'), ('decade code', 'int')]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get columns and data types\n",
    "print(\"\"\"\n",
    "Pandas db.columns:\n",
    "===================\n",
    "{}\n",
    "\n",
    "PySpark df.columns:\n",
    "===================\n",
    "{}\n",
    "\n",
    "Pandas db.dtype:\n",
    "===================\n",
    "{}\n",
    "\n",
    "PySpark df.dtypes:\n",
    "===================\n",
    "{}\n",
    "\n",
    "\"\"\".format(db.columns, df.columns, db.dtypes, df.dtypes), flush = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T08:55:19.717696Z",
     "start_time": "2020-06-19T08:55:19.671673Z"
    }
   },
   "outputs": [],
   "source": [
    "# pandas add a column\n",
    "db['newcol'] = db.domgross/db.intgross\n",
    "\n",
    "# pyspark add a column\n",
    "df=df.withColumn('newcol', df.domgross/df.intgross)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T08:55:20.411358Z",
     "start_time": "2020-06-19T08:55:20.383463Z"
    }
   },
   "outputs": [],
   "source": [
    "# pandas rename columns\n",
    "db.rename(columns={'newcol': 'dgs/igs'}, inplace=True)\n",
    "\n",
    "# pyspark rename columns\n",
    "df=df.withColumnRenamed('newcol', 'dgs/igs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-06T08:44:37.205943Z",
     "start_time": "2020-06-06T08:44:37.202051Z"
    }
   },
   "source": [
    "## Drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T08:55:22.433936Z",
     "start_time": "2020-06-19T08:55:22.395441Z"
    }
   },
   "outputs": [],
   "source": [
    "# pandas drop `code' column\n",
    "db.drop('code', axis=1, inplace=True)\n",
    "\n",
    "# pyspark drop `code' column\n",
    "df=df.drop('code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T08:55:23.110718Z",
     "start_time": "2020-06-19T08:55:23.076353Z"
    }
   },
   "outputs": [],
   "source": [
    "# pandas dropna()\n",
    "db.dropna(subset=['domgross'], inplace=True)\n",
    "\n",
    "# pyspark dropna()\n",
    "df=df.dropna(subset='domgross')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T08:55:25.772431Z",
     "start_time": "2020-06-19T08:55:25.717212Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>budget</th>\n",
       "      <th>domgross</th>\n",
       "      <th>intgross</th>\n",
       "      <th>budget_2013$</th>\n",
       "      <th>domgross_2013$</th>\n",
       "      <th>intgross_2013$</th>\n",
       "      <th>period code</th>\n",
       "      <th>decade code</th>\n",
       "      <th>dgs/igs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1777.000000</td>\n",
       "      <td>1.777000e+03</td>\n",
       "      <td>1.777000e+03</td>\n",
       "      <td>1.777000e+03</td>\n",
       "      <td>1.777000e+03</td>\n",
       "      <td>1.776000e+03</td>\n",
       "      <td>1.777000e+03</td>\n",
       "      <td>1601.000000</td>\n",
       "      <td>1601.000000</td>\n",
       "      <td>1777.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2002.541925</td>\n",
       "      <td>4.515912e+07</td>\n",
       "      <td>6.913205e+07</td>\n",
       "      <td>1.508502e+08</td>\n",
       "      <td>5.586937e+07</td>\n",
       "      <td>9.517478e+07</td>\n",
       "      <td>1.984575e+08</td>\n",
       "      <td>2.425984</td>\n",
       "      <td>1.939413</td>\n",
       "      <td>0.591354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.956449</td>\n",
       "      <td>4.828677e+07</td>\n",
       "      <td>8.036731e+07</td>\n",
       "      <td>2.105371e+08</td>\n",
       "      <td>5.501093e+07</td>\n",
       "      <td>1.259653e+08</td>\n",
       "      <td>2.837846e+08</td>\n",
       "      <td>1.197257</td>\n",
       "      <td>0.691521</td>\n",
       "      <td>0.260125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1970.000000</td>\n",
       "      <td>7.000000e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.280000e+02</td>\n",
       "      <td>8.632000e+03</td>\n",
       "      <td>8.990000e+02</td>\n",
       "      <td>8.990000e+02</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1998.000000</td>\n",
       "      <td>1.200000e+07</td>\n",
       "      <td>1.631157e+07</td>\n",
       "      <td>2.634190e+07</td>\n",
       "      <td>1.623422e+07</td>\n",
       "      <td>2.054659e+07</td>\n",
       "      <td>3.370383e+07</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.400251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2005.000000</td>\n",
       "      <td>3.000000e+07</td>\n",
       "      <td>4.219406e+07</td>\n",
       "      <td>7.695431e+07</td>\n",
       "      <td>3.715744e+07</td>\n",
       "      <td>5.599364e+07</td>\n",
       "      <td>9.684656e+07</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.540907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2009.000000</td>\n",
       "      <td>6.000000e+07</td>\n",
       "      <td>9.335492e+07</td>\n",
       "      <td>1.904000e+08</td>\n",
       "      <td>7.894273e+07</td>\n",
       "      <td>1.216784e+08</td>\n",
       "      <td>2.419194e+08</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.789224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2013.000000</td>\n",
       "      <td>4.250000e+08</td>\n",
       "      <td>7.605076e+08</td>\n",
       "      <td>2.783919e+09</td>\n",
       "      <td>4.614359e+08</td>\n",
       "      <td>1.771683e+09</td>\n",
       "      <td>3.171931e+09</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              year        budget      domgross      intgross  budget_2013$  \\\n",
       "count  1777.000000  1.777000e+03  1.777000e+03  1.777000e+03  1.777000e+03   \n",
       "mean   2002.541925  4.515912e+07  6.913205e+07  1.508502e+08  5.586937e+07   \n",
       "std       8.956449  4.828677e+07  8.036731e+07  2.105371e+08  5.501093e+07   \n",
       "min    1970.000000  7.000000e+03  0.000000e+00  8.280000e+02  8.632000e+03   \n",
       "25%    1998.000000  1.200000e+07  1.631157e+07  2.634190e+07  1.623422e+07   \n",
       "50%    2005.000000  3.000000e+07  4.219406e+07  7.695431e+07  3.715744e+07   \n",
       "75%    2009.000000  6.000000e+07  9.335492e+07  1.904000e+08  7.894273e+07   \n",
       "max    2013.000000  4.250000e+08  7.605076e+08  2.783919e+09  4.614359e+08   \n",
       "\n",
       "       domgross_2013$  intgross_2013$  period code  decade code      dgs/igs  \n",
       "count    1.776000e+03    1.777000e+03  1601.000000  1601.000000  1777.000000  \n",
       "mean     9.517478e+07    1.984575e+08     2.425984     1.939413     0.591354  \n",
       "std      1.259653e+08    2.837846e+08     1.197257     0.691521     0.260125  \n",
       "min      8.990000e+02    8.990000e+02     1.000000     1.000000     0.000000  \n",
       "25%      2.054659e+07    3.370383e+07     1.000000     1.000000     0.400251  \n",
       "50%      5.599364e+07    9.684656e+07     2.000000     2.000000     0.540907  \n",
       "75%      1.216784e+08    2.419194e+08     3.000000     2.000000     0.789224  \n",
       "max      1.771683e+09    3.171931e+09     5.000000     3.000000     1.000000  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pandas describe\n",
    "db.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T08:55:28.562107Z",
     "start_time": "2020-06-19T08:55:27.881541Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+--------------------+\n",
      "|summary|             year|              budget|\n",
      "+-------+-----------------+--------------------+\n",
      "|  count|             1794|                1794|\n",
      "|   mean|2002.552396878484|4.4826462614269786E7|\n",
      "| stddev|8.979730993075055| 4.818602611895356E7|\n",
      "|    min|             1970|                7000|\n",
      "|    max|             2013|           425000000|\n",
      "+-------+-----------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# pyspark describe\n",
    "df.describe(['year', 'budget']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T10:17:13.644915Z",
     "start_time": "2020-06-10T10:17:13.638567Z"
    }
   },
   "source": [
    "# Pyspark and SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T11:08:57.097001Z",
     "start_time": "2020-06-19T11:08:57.061368Z"
    }
   },
   "outputs": [],
   "source": [
    "# pyspark rename 'budget_2013$'\n",
    "df=df.withColumnRenamed('budget_2013$', 'budget_2013')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T11:10:17.413884Z",
     "start_time": "2020-06-19T11:10:16.590406Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+----------------+--------+\n",
      "|     imdb|year|           title|  budget|\n",
      "+---------+----+----------------+--------+\n",
      "|tt1711425|2013|   21 &amp; Over|13000000|\n",
      "|tt1343727|2012|        Dredd 3D|45000000|\n",
      "|tt2024544|2013|12 Years a Slave|20000000|\n",
      "|tt1272878|2013|          2 Guns|61000000|\n",
      "|tt0453562|2013|              42|40000000|\n",
      "+---------+----+----------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a temporary table \n",
    "df.createOrReplaceTempView('bechdel')\n",
    "\n",
    "# Run a simple SQL command\n",
    "sql = spark.sql(\"\"\"SELECT imdb, year, title, budget FROM bechdel LIMIT(5)\"\"\")\n",
    "sql.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T11:14:53.890743Z",
     "start_time": "2020-06-19T11:14:51.360644Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+-------------+---------------+--------------+-------------------+\n",
      "|binary|count|   avg_budget|avg_budget_samp|avg_budget2013|avg_budget2013_samp|\n",
      "+------+-----+-------------+---------------+--------------+-------------------+\n",
      "|  FAIL|  991|50,415,289.27|  44,826,462.61| 62,911,555.33|      55,464,608.45|\n",
      "|  PASS|  803|37,929,168.45|  44,826,462.61| 46,274,167.16|      55,464,608.45|\n",
      "+------+-----+-------------+---------------+--------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# AVG budget differences\n",
    "sql_avg = spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT \n",
    "    binary, \n",
    "    COUNT(*) AS count, \n",
    "    format_number(AVG(budget),2) AS avg_budget, \n",
    "    format_number((SELECT AVG(budget) FROM bechdel),2) AS avg_budget_samp,\n",
    "    format_number(AVG(budget_2013),2) AS avg_budget2013,\n",
    "    format_number((SELECT AVG(budget_2013) FROM bechdel),2) AS avg_budget2013_samp\n",
    "    FROM bechdel GROUP BY binary\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "sql_avg.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data from DBMS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run the following you need to restart the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T11:23:01.648047Z",
     "start_time": "2020-06-19T11:23:01.583515Z"
    }
   },
   "outputs": [],
   "source": [
    "# to create a spark session object\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PostgreSQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To interact with postgre you need to:\n",
    "    \n",
    "* Download the *postgresql-42.2.14.jar file* [here](https://jdbc.postgresql.org/download.html)\n",
    "* Include the path to the downloaded jar file into SparkSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T11:18:43.342799Z",
     "start_time": "2020-06-19T11:18:38.676180Z"
    }
   },
   "outputs": [],
   "source": [
    "# Open a session running data from PostgreSQL\n",
    "spark_postgre = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"last_dance_postgre\") \\\n",
    "    .config(\"spark.jars\", \"/Users/matteo/py3_venvs/smm695/share/py4j/postgresql-42.2.14.jar\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T11:18:44.820975Z",
     "start_time": "2020-06-19T11:18:44.797346Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://172.20.10.2:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.6</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>last_dance_postgre</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x103336990>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_postgre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T11:20:43.104781Z",
     "start_time": "2020-06-19T11:20:41.653768Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- film_id: integer (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      " |-- release_year: integer (nullable = true)\n",
      " |-- language_id: short (nullable = true)\n",
      " |-- original_language_id: short (nullable = true)\n",
      " |-- rental_duration: short (nullable = true)\n",
      " |-- rental_rate: decimal(4,2) (nullable = true)\n",
      " |-- length: short (nullable = true)\n",
      " |-- replacement_cost: decimal(5,2) (nullable = true)\n",
      " |-- rating: string (nullable = true)\n",
      " |-- last_update: timestamp (nullable = true)\n",
      " |-- special_features: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- fulltext: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read data from PostgreSQL running at localhost\n",
    "df = spark_postgre.read \\\n",
    "    .format(\"jdbc\") \\\n",
    "    .option(\"url\", \"jdbc:postgresql://localhost:5433/pagila\") \\\n",
    "    .option(\"dbtable\", \"film\") \\\n",
    "    .option(\"user\", \"postgres\") \\\n",
    "    .option(\"password\", \"smm695\") \\\n",
    "    .option(\"driver\", \"org.postgresql.Driver\") \\\n",
    "    .load()\n",
    "\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T11:21:08.771475Z",
     "start_time": "2020-06-19T11:21:05.732524Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+-----------------+------------------+\n",
      "|summary|release_year|      rental_rate|   rental_duration|\n",
      "+-------+------------+-----------------+------------------+\n",
      "|  count|        1000|             1000|              1000|\n",
      "|   mean|      2006.0|         2.980000|             4.985|\n",
      "| stddev|         0.0|1.646393212635005|1.4116542663725307|\n",
      "|    min|        2006|             0.99|                 3|\n",
      "|    max|        2006|             4.99|                 7|\n",
      "+-------+------------+-----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get some stats\n",
    "df.describe(['release_year', 'rental_rate', 'rental_duration']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T11:22:06.426641Z",
     "start_time": "2020-06-19T11:22:05.835428Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------------+------+------+\n",
      "|           title|release_year|length|rating|\n",
      "+----------------+------------+------+------+\n",
      "|ACADEMY DINOSAUR|        2006|    86|    PG|\n",
      "+----------------+------------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a temporary table \n",
    "df.createOrReplaceTempView('film')\n",
    "\n",
    "# Run a simple SQL command\n",
    "sql = spark_postgre.sql(\"\"\"SELECT title, release_year, length, rating FROM film LIMIT(1)\"\"\")\n",
    "sql.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MongoDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For further reference check the [Python Guide provided by Mongo](https://docs.mongodb.com/spark-connector/current/python-api/) or the [website for the mongo-spark connector](https://spark-packages.org/package/mongodb/mongo-spark)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T11:25:16.920144Z",
     "start_time": "2020-06-19T11:25:10.141682Z"
    }
   },
   "outputs": [],
   "source": [
    "# add path to Mongo\n",
    "spark_mongo = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"last_dance_mongo\") \\\n",
    "    .config(\"spark.mongodb.input.uri\", \"mongodb://127.0.0.1/amazon.music\") \\\n",
    "    .config(\"spark.mongodb.output.uri\", \"mongodb://127.0.0.1/amazon.music\") \\\n",
    "    .config('spark.jars.packages', 'org.mongodb.spark:mongo-spark-connector_2.11:2.4.1') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T11:25:21.410330Z",
     "start_time": "2020-06-19T11:25:21.375456Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://172.20.10.2:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.6</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>last_dance_mongo</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x10f3cea90>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_mongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T11:26:05.596318Z",
     "start_time": "2020-06-19T11:26:02.191328Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _id: struct (nullable = true)\n",
      " |    |-- oid: string (nullable = true)\n",
      " |-- asin: string (nullable = true)\n",
      " |-- date: timestamp (nullable = true)\n",
      " |-- helpful: array (nullable = true)\n",
      " |    |-- element: integer (containsNull = true)\n",
      " |-- overall: integer (nullable = true)\n",
      " |-- reviewText: string (nullable = true)\n",
      " |-- reviewTime: string (nullable = true)\n",
      " |-- reviewerID: string (nullable = true)\n",
      " |-- reviewerName: string (nullable = true)\n",
      " |-- summary: string (nullable = true)\n",
      " |-- unixReviewTime: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load data from MongoDB\n",
    "df = spark_mongo.read.format(\"mongo\").load()\n",
    "\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T11:26:26.487659Z",
     "start_time": "2020-06-19T11:26:20.795549Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+--------------------+\n",
      "|summary|           overall|      unixReviewTime|\n",
      "+-------+------------------+--------------------+\n",
      "|  count|           1097592|             1097592|\n",
      "|   mean| 4.294394456227815|1.1741746688824263E9|\n",
      "| stddev|1.0737318641546316| 1.363032651590121E8|\n",
      "|    min|                 1|           879292800|\n",
      "|    max|                 5|          1406073600|\n",
      "+-------+------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get some stats\n",
    "df.describe(['overall', 'unixReviewTime']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T11:27:28.119177Z",
     "start_time": "2020-06-19T11:27:16.008431Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------+--------+-------+--------------+\n",
      "|      asin|               date| helpful|overall|unixReviewTime|\n",
      "+----------+-------------------+--------+-------+--------------+\n",
      "|0307141985|2005-10-06 02:00:00|[14, 15]|      5|    1128556800|\n",
      "+----------+-------------------+--------+-------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a temporary table \n",
    "df.createOrReplaceTempView('music')\n",
    "\n",
    "# Run a simple SQL command\n",
    "sql = spark_mongo.sql(\"\"\"SELECT asin, date, helpful, overall, unixReviewTime FROM music LIMIT(1)\"\"\")\n",
    "sql.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "* Bill Chambers, Matei Zaharia 2018,[\"Spark: The Definitive Guide\"](https://www.oreilly.com/library/view/spark-the-definitive/9781491912201/) <img src=\"images/_3.png\" width=\"20%\">\n",
    "* Pramod Singh 2019, [\"Learn PySpark: Build Python-based Machine Learning and Deep Learning Models\n",
    "\"](https://www.ibs.it/learn-pyspark-build-python-based-libro-inglese-pramod-singh/e/9781484249604) <img src=\"images/_4.png\" width=\"18%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "198px",
    "left": "1089px",
    "right": "20px",
    "top": "120px",
    "width": "331px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
